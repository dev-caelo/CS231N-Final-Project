{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (4.41.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (3.5.3)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (0.18.0)\n",
      "Requirement already satisfied: kaggle in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (1.6.14)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.4.1.post1)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Initial setup cell\n",
    "!pip3 install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup\n",
    "Initializes our train and test set and stores the ground truth of each image. We use Torch libraries to handle this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data setup dependencies from Torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our lung_image_sets\n",
    "data_dir = \"../../lung_colon_image_set/lung_image_sets\"\n",
    "\n",
    "# Convert images into Tensors\n",
    "tensor_data = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "data = ImageFolder(root=data_dir, transform=tensor_data)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train, test = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "load_train = DataLoader(train, batch_size=32, shuffle=True)\n",
    "load_test = DataLoader(test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGW-Net: A basic CNN image classifier\n",
    "\n",
    "DGW-Net (abbreviated from Dino-Garcia-Wang Net) is a simple CNN architecture that follows the structure below:\n",
    "- Input -> CONV (3x3, 64 filters) -> ReLU -> MaxPool -> CONV (3x3, 64 filters) -> ReLU -> MaxPool -> FC\n",
    "\n",
    "This model architecture follows from our simple CNN implementation for CIFAR-10 on Assignment 2. We decided on 64 filters as empirically this number has proven to be successful in models like ResNet. The implementation follows below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our DGW-Net Architecture\n",
    "class DGWNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DGWNet, self).__init__()\n",
    "        \n",
    "        # First convolutional block: 64 filters used. (768, 768, 3) -> (384, 384, 64)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second convolutional block: 64 filters used. (384, 384, 64) -> (192, 192, 64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # FC Layer -> 128 Features\n",
    "        self.fc = nn.Linear(192 * 192 * 64, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First convolutional block\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten the output from the convolutional blocks\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layer for classification\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGW-Net + SVM\n",
    "For our first situation, we will use SVM to do classification on our extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGWSVM(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(DGWSVM, self).__init__()\n",
    "      \n",
    "      # Base DGWNet feature extractor -> 128 features\n",
    "      self.extract_features = DGWNet()\n",
    "      \n",
    "      # SVM layer\n",
    "      self.svm = nn.Linear(128, 3) \n",
    "  \n",
    "  def forward(self, x):\n",
    "        # Pass the input through the base CNN\n",
    "        x = self.extract_features(x)\n",
    "        \n",
    "        # SVM layer\n",
    "        x = self.svm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define instance of our model\n",
    "model = DGWNet()\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 5e-3\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
