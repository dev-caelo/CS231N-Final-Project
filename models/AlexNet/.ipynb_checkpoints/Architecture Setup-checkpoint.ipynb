{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f9d119-1c9c-4d1b-923b-e6bd49f45b5f",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Hello! Welcome to the architecture setup notebook, where we will be installing all requirements and outline the basic architecture of our AlexNet model (whose performance will be compared to our custom model, EfficentNet, and ConvNeXt). \n",
    "\n",
    "\n",
    "The cell below handles our initial requirements installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e7b0f3-17de-4abc-bdd0-ea94640db448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: transformers in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 2)) (4.41.1)\n",
      "Requirement already satisfied: matplotlib in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 3)) (3.7.2)\n",
      "Requirement already satisfied: torch in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: torchvision in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 5)) (0.17.0)\n",
      "Requirement already satisfied: kaggle in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 6)) (1.6.14)\n",
      "Requirement already satisfied: scikit-learn in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: tensorflow in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: keras in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 9)) (2.12.0)\n",
      "Requirement already satisfied: seaborn in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 10)) (0.13.2)\n",
      "Requirement already satisfied: pandas in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from -r ../../requirements.txt (line 11)) (2.0.3)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: requests in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (0.19.1)\n",
      "Requirement already satisfied: filelock in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from transformers->-r ../../requirements.txt (line 2)) (0.23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (6.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (10.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from torch->-r ../../requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from torch->-r ../../requirements.txt (line 4)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from torch->-r ../../requirements.txt (line 4)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from torch->-r ../../requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from torch->-r ../../requirements.txt (line 4)) (2024.5.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from kaggle->-r ../../requirements.txt (line 6)) (2024.2.2)\n",
      "Requirement already satisfied: bleach in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from kaggle->-r ../../requirements.txt (line 6)) (6.1.0)\n",
      "Requirement already satisfied: urllib3 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from kaggle->-r ../../requirements.txt (line 6)) (1.26.18)\n",
      "Requirement already satisfied: python-slugify in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from kaggle->-r ../../requirements.txt (line 6)) (8.0.4)\n",
      "Requirement already satisfied: six>=1.10 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from kaggle->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from scikit-learn->-r ../../requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from scikit-learn->-r ../../requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from scikit-learn->-r ../../requirements.txt (line 7)) (1.10.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (24.3.25)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (1.14.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (1.64.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (4.25.3)\n",
      "Requirement already satisfied: jax>=0.3.15 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (0.4.13)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (0.34.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (2.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (65.5.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorflow->-r ../../requirements.txt (line 8)) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from pandas->-r ../../requirements.txt (line 11)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from pandas->-r ../../requirements.txt (line 11)) (2023.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->-r ../../requirements.txt (line 8)) (0.37.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->-r ../../requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow->-r ../../requirements.txt (line 8)) (7.1.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow->-r ../../requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (3.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (2.29.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from requests->transformers->-r ../../requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from requests->transformers->-r ../../requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: webencodings in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from bleach->kaggle->-r ../../requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from jinja2->torch->-r ../../requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from python-slugify->kaggle->-r ../../requirements.txt (line 6)) (1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from sympy->torch->-r ../../requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (5.3.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nicolegarcia/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r ../../requirements.txt (line 8)) (3.2.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d52aad-b30b-493d-ba92-5037af2e7f0a",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "As part of our data preprocessing, we will split the down-scaled lung dataset from the original dataset into a train/test split. \n",
    "\n",
    "Note that we will be using five-fold cross-validation for testing later, hence we will not be partioning an additional validation set. \n",
    "\n",
    "After splitting our data, we will then feed the training set into our models. Here, we will specifically feed it into the AlexNet model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b162f0-bf43-4f54-b158-99fea42dffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a733a84b-4a8a-467a-a710-00481ee33691",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The code below extracts images from our dataset, resizes each into a fourth their original size (768 -> 192), and converts them into Torch tensors. The ImageFolder class allows us to lazyload our images to preserve our computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b130d35-ed66-48f9-8bc4-70d63be800f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our lung_image_sets\n",
    "data_dir = \"../../lung_colon_image_set/lung_image_sets\"\n",
    "\n",
    "# Define resized size of images\n",
    "resized_size = 192\n",
    "\n",
    "# Convert images into Tensors\n",
    "tensor_data = transforms.Compose([\n",
    "  transforms.Resize((resized_size, resized_size)),   # Cut image into a fourth of original size\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "data = ImageFolder(root=data_dir, transform=tensor_data)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train, test = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "load_train = DataLoader(train, batch_size=32, shuffle=True)\n",
    "load_test = DataLoader(test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493416c-19f2-4ec5-b0fc-55087b8258bd",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "We will initialize the AlexNet model using Pytorch's pretrained AlexNet model and remove the final layer to perform feature extraction on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5eb6da-8330-44ec-96d5-ead70efe5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolegarcia/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nicolegarcia/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize AlexNet Model \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify AlexNet to Extract Features\n",
    "# Note: we are removing the final layer\n",
    "model = torch.nn.Sequential(*list(alexnet.children())[:-1])\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 5e-4\n",
    "momentum = 0.9\n",
    "\n",
    "# Define our loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c870c-0c29-479f-9ac4-7e24f497bf26",
   "metadata": {},
   "source": [
    "## AlexNet + SVM Classifier Training and Testing\n",
    "We will perform k-fold cross-validation testing on the SVM classifier, which is trained the on features extracted by our AlexNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb72148-5f67-42da-89be-47f3d424677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 1 Accuracy: 0.9623\n",
      "Fold 2\n",
      "Fold 2 Accuracy: 0.9563\n",
      "Fold 3\n",
      "Fold 3 Accuracy: 0.9650\n",
      "Fold 4\n",
      "Fold 4 Accuracy: 0.9657\n",
      "Fold 5\n",
      "Fold 5 Accuracy: 0.9647\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 1: 0.9623\n",
      "Fold 2: 0.9563\n",
      "Fold 3: 0.9650\n",
      "Fold 4: 0.9657\n",
      "Fold 5: 0.9647\n",
      "Average: 0.9628\n"
     ]
    }
   ],
   "source": [
    "# Store the results of each fold\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=231)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(data), 1):\n",
    "    print(f'Fold {fold}')\n",
    "\n",
    "    # Create data samplers for train and validation sets\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    # Create data loaders for train and validation sets\n",
    "    train_loader = DataLoader(data, batch_size=32, sampler=train_sampler)\n",
    "    val_loader = DataLoader(data, batch_size=32, sampler=val_sampler)\n",
    "    \n",
    "    # Extract features and labels for the training set\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "            train_features.append(outputs.cpu().numpy())\n",
    "            train_labels.append(labels.cpu().numpy())\n",
    "    train_features = np.concatenate(train_features)\n",
    "    train_labels = np.concatenate(train_labels)\n",
    "    \n",
    "    # Extract features and labels for the validation set\n",
    "    val_features = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "            val_features.append(outputs.cpu().numpy())\n",
    "            val_labels.append(labels.cpu().numpy())\n",
    "    val_features = np.concatenate(val_features)\n",
    "    val_labels = np.concatenate(val_labels)\n",
    "\n",
    "    # Create and train the SVM classifier\n",
    "    svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "    svm_model.fit(train_features, train_labels)\n",
    "\n",
    "    # Evaluate the classifier on the validation set\n",
    "    val_predictions = svm_model.predict(val_features)\n",
    "    accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    results[fold] = accuracy\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "average_accuracy = np.mean(list(results.values()))\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {num_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "for fold in results:\n",
    "    print(f'Fold {fold}: {results[fold]:.4f}')\n",
    "print(f'Average: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c0991-e26b-4c2c-85da-e4c7c60eb54c",
   "metadata": {},
   "source": [
    "## AlexNet + Softmax Classifier Training and Testing\n",
    "We will perform k-fold cross-validation testing on the Softmax classifier, which is trained the on features extracted by our AlexNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b6ff12-1f1c-490c-9aab-6071a18deb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m outputs \u001b[38;5;241m=\u001b[39m alexnet(inputs)\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 5e-4\n",
    "momentum = 0.9\n",
    "num_epochs = 5  # Number of epochs for training\n",
    "num_folds = 5\n",
    "\n",
    "# Load the pre-trained AlexNet model\n",
    "model_ = alexnet\n",
    "num_features = model_.classifier[6].in_features\n",
    "model_.classifier[6] = nn.Linear(num_features, len(data.classes))\n",
    "model_ = model_.to(device)\n",
    "\n",
    "# Store the results of each fold\n",
    "results = {}\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(data), 1):\n",
    "    print(f'Fold {fold}')\n",
    "\n",
    "    # Create data samplers for train and validation sets\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    # Create data loaders for train and validation sets\n",
    "    train_loader = DataLoader(data, batch_size=32, sampler=train_sampler)\n",
    "    val_loader = DataLoader(data, batch_size=32, sampler=val_sampler)\n",
    "    \n",
    "    # Define the optimizer\n",
    "    optimizer = optim.SGD(alexnet.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    # Train the model\n",
    "    alexnet.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = alexnet(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    alexnet.eval()\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_predictions = []\n",
    "    val_labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = alexnet(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_predictions.extend(preds.cpu().numpy())\n",
    "            val_labels_list.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(val_labels_list, val_predictions)\n",
    "    results[fold] = accuracy\n",
    "    print(f'Fold {fold} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "average_accuracy = np.mean(list(results.values()))\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {num_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "for fold in results:\n",
    "    print(f'Fold {fold}: {results[fold]:.4f}')\n",
    "print(f'Average: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f38a84-a9b4-4c45-926d-374addda5dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
